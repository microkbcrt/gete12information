import requests
import json
from datetime import datetime
from bs4 import BeautifulSoup
import os  # å¯¼å…¥osåº“æ¥è¯»å–ç¯å¢ƒå˜é‡

# --- é…ç½®åŒº ---
HOST_MID = "1636034895"
OUTPUT_FILENAME = 'latest_bili_phigros_post.json' # ä¿®æ”¹äº†è¾“å‡ºæ–‡ä»¶åä»¥åŒºåˆ†

# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–SESSDATAï¼Œè¿™æ˜¯åœ¨GitHub Actionsä¸­ä½¿ç”¨çš„æœ€ä½³å®è·µ
# os.environ.get('BILI_SESSDATA') ä¼šå°è¯•è¯»å–åä¸º BILI_SESSDATA çš„ç¯å¢ƒå˜é‡
# å¦‚æœåœ¨æœ¬åœ°æµ‹è¯•ï¼Œä½ å¯ä»¥æ‰‹åŠ¨è®¾ç½®è¿™ä¸ªç¯å¢ƒå˜é‡ï¼Œæˆ–è€…ä¸´æ—¶åœ¨è¿™é‡Œèµ‹å€¼
SESSDATA = os.environ.get('BILI_SESSDATA')

def scrape_opus_page_content(opus_url, headers):
    # ... (è¿™éƒ¨åˆ†å‡½æ•°å’Œä¹‹å‰å®Œå…¨ä¸€æ ·ï¼Œæ— éœ€ä¿®æ”¹) ...
    print(f"æ­£åœ¨æŠ“å–åŠ¨æ€è¯¦æƒ…é¡µ: {opus_url}")
    try:
        response = requests.get(opus_url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'lxml')
        content_div = soup.find('div', class_='opus-module-content')
        if content_div:
            full_text = content_div.get_text(separator='\n', strip=True)
            return full_text
        else:
            return "[æŠ“å–é”™è¯¯] åœ¨é¡µé¢ä¸­æœªèƒ½æ‰¾åˆ° 'opus-module-content' å®¹å™¨ã€‚"
    except requests.exceptions.RequestException as e:
        print(f"æŠ“å–è¯¦æƒ…é¡µå¤±è´¥: {e}")
        return f"[ç½‘ç»œé”™è¯¯] æ— æ³•è®¿é—®åŠ¨æ€è¯¦æƒ…é¡µ: {opus_url}"
    except Exception as e:
        print(f"è§£æHTMLæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return "[è§£æé”™è¯¯] è§£æè¯¦æƒ…é¡µHTMLæ—¶å‡ºé”™ã€‚"

def fetch_and_process_dynamics():
    api_url = f"https://api.bilibili.com/x/polymer/web-dynamic/v1/feed/space?host_mid={HOST_MID}"

    # åœ¨è„šæœ¬å¼€å§‹æ—¶å°±æ£€æŸ¥SESSDATAæ˜¯å¦å­˜åœ¨
    if not SESSDATA:
        print("é”™è¯¯ï¼šç¯å¢ƒå˜é‡ BILI_SESSDATA æœªè®¾ç½®ï¼è¯·åœ¨GitHub Secretsä¸­æ·»åŠ å®ƒã€‚")
        # ä½¿ç”¨ exit(1) æ¥ä½¿å·¥ä½œæµæ­¥éª¤å¤±è´¥ï¼Œè¿™æ ·æ›´å®¹æ˜“å‘ç°é—®é¢˜
        exit(1)

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
        'Cookie': f'SESSDATA={SESSDATA}',
        'Referer': f'https://space.bilibili.com/{HOST_MID}/dynamic'
    }

    print(f"ç¬¬ä¸€æ­¥ï¼šæ­£åœ¨é€šè¿‡APIè·å–ç”¨æˆ·(UID: {HOST_MID})çš„åŠ¨æ€åˆ—è¡¨...")
    
    try:
        response = requests.get(api_url, headers=headers, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if data.get('code') != 0:
            print(f"APIè¿”å›é”™è¯¯ï¼ ä»£ç : {data.get('code')}, ä¿¡æ¯: {data.get('message', 'æ— ')}")
            exit(1) # APIå‡ºé”™ä¹Ÿç›´æ¥è®©å·¥ä½œæµå¤±è´¥

        items_list = data.get('data', {}).get('items')
        if not items_list:
            print("APIè¿”å›çš„æ•°æ®ä¸­æœªæ‰¾åˆ°åŠ¨æ€åˆ—è¡¨ã€‚")
            return

        latest_post = max(items_list, key=lambda item: item.get('modules', {}).get('module_author', {}).get('pub_ts', 0))
        
        dynamic_id = latest_post.get('id_str')
        if not dynamic_id:
            print("é”™è¯¯ï¼šæ— æ³•ä»æœ€æ–°çš„åŠ¨æ€ä¸­æå–åˆ° 'id_str'ã€‚")
            exit(1)

        opus_url = f"https://www.bilibili.com/opus/{dynamic_id}"
        print(f"\nç¬¬äºŒæ­¥ï¼šå·²æ‰¾åˆ°æœ€æ–°åŠ¨æ€ID({dynamic_id})ï¼Œå‡†å¤‡æŠ“å–è¯¦æƒ…é¡µã€‚")
        
        final_content = scrape_opus_page_content(opus_url, headers)
        
        publish_timestamp = latest_post.get('modules', {}).get('module_author', {}).get('pub_ts', 0)
        publish_time_str = datetime.fromtimestamp(publish_timestamp).strftime('%Y-%m-%d %H:%M:%S')

        final_data = {
            "publish_time": publish_time_str,
            "dynamic_url": opus_url,
            "content": final_content
        }

        with open(OUTPUT_FILENAME, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=4)

        print(f"\nğŸ‰ ä»»åŠ¡å®Œæˆï¼è¯¦ç»†å†…å®¹å·²ä¿å­˜åˆ°æ–‡ä»¶: {OUTPUT_FILENAME}")
        
    except requests.exceptions.RequestException as e:
        print(f"APIè¯·æ±‚å¤±è´¥: {e}")
        exit(1)
    except Exception as e:
        print(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        exit(1)

if __name__ == "__main__":
    fetch_and_process_dynamics()
